<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
    <meta name="description" content="Check out the SWT-Bench leaderboard! SWT-Bench is a benchmark designed to assess the capabilities of large language models and Code Agents in generating unit tests on real-world code repositories, developed by ETH Zurich.">
  <meta name="keywords" content="language models, unit test, software testing, repository, swebench, software engineering, benchmark, agents, code agents, code models, AI, artificial intelligence, machine learning, NLP, natural language processing, automated testing, test generation, LLM, large language models, hallucination detection, ETH ZÃ¼rich, SRI Lab">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"/>
  
  <!-- Primary Meta Tags -->
  <title>SWT-Bench: Assessing capabilities at Unit Test Generation</title>
  <meta name="title" content="SWT-Bench: Assessing capabilities at Unit Test Generation">
  <meta name="description" content="Check out the SWT-Bench leaderboard! SWT-Bench is a benchmark designed to assess the capabilities of large language models and Code Agents in generating unit tests on real-world code repositories, developed by Logic Star AI and ETH Zurich.">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://swtbench.com/">
  <meta property="og:title" content="SWT-Bench: Assessing capabilities at Unit Test Generation">
  <meta property="og:description" content="Check out the SWT-Bench leaderboard! SWT-Bench is a benchmark designed to assess the capabilities of large language models and Code Agents in generating unit tests on real-world code repositories, developed by ETH Zurich.">
  <meta property="og:image" content="https://swtbench.com/static/images/social.png">
  <meta property="og:image:alt" content="A GitHub issue, a robot generating code, and test case passing indications. The project is developed by Logic Star AI and SRI Lab at ETH ZÃ¼rich.">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:url" content="https://swtbench.com/">
  <meta property="twitter:title" content="SWT-Bench: Assessing capabilities at Unit Test Generation">
  <meta property="twitter:description" content="Check out the SWT-Bench leaderboard! SWT-Bench is a benchmark designed to assess the capabilities of large language models and Code Agents in generating unit tests on real-world code repositories, developed by ETH Zurich.">
  <meta property="twitter:image" content="https://swtbench.com/static/images/social.png">
  <meta property="twitter:image:alt" content="A GitHub issue, a robot generating code, and test case passing indications. The project is developed by Logic Star AI and SRI Lab at ETH ZÃ¼rich.">
  
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.svg">
  <link rel="stylesheet" href="./static/css/val.gen.css">
  <link rel="stylesheet" href="./static/css/chatprotect.css">
  <link rel="stylesheet" href="./static/css/highlight.min.css">
  <script src="https://kit.fontawesome.com/06bb68d804.js" crossorigin="anonymous"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./static/js/highlight.min.js"></script>
  <script src="./static/js/swtbench.js"></script>
  <script type="text/javascript" id="MathJax-script" async src="./static/js/tex-mml-svg.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-solarizedlight.min.css"/>



<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-MNMN06N76C"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-MNMN06N76C');
</script>

</head>
<body>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js">
</script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs-bibtex@2.1.0/prism-bibtex.min.js"></script>
  <div class="topnav">
    <a href="./">
      <table class="logo">
        <tr>
          <td>
            <div class="is-hidden-mobile">SWT-Bench</div>
          </td>
          <td>
            &nbsp;
            <img src="./static/images/logo-cropped.svg" alt="ðŸ›ðŸ”" class="inline-emoji">
          </td>
        </tr>
      </table>
    </a>
    <a href="#about">
      <table>
        <tr>
          <td>
            <img src="./static/images/emojis/2139.svg" alt="â„¹ï¸" class="inline-emoji">
          </td>
          <td>
            &nbsp; About
          </td>
        </tr>
      </table>
    </a>
    <a href="#learn-more">
      <table>
        <tr>
          <td>
            <img src="./static/images/emojis/1F4DC.svg" alt="ðŸ“œ" class="inline-emoji">
          </td>
          <td>
            &nbsp; Paper &amp; Code
          </td>
        </tr>
      </table>
    </a>
    <span>&nbsp;&nbsp;</span>
  </div>

<section class="hero is-align-items-center is-link">
  <div class="hero-body">
    <p class="subtitle">
    SWT-Bench is a benchmark for software testing capabilities on real-world code bases.
    </p>
    <p style="max-width: 750px;">
       SWT-Bench is based on real-world GitHub issues and pull-requests of popular python libraries. Given the code base and a user-reported issue, the task is to generate a reproducing test. A test is considered to be reproducing if it fails on the original code base but passes after the pull-request resolving the issue has been applied. 
       </p>
    </p>
    </div>
    </p>
  </div>
</section>

  <section class="section">
    <div class="container is-max-desktop"> 
      <div class="columns is-centered">
        <div class="column">

          <div class="table-container">
      <table id="leaderboard-table" class="table is-hoverable is-fullwidth">
        <thead>
          <tr>
            <th style="width: 60%;">Model <span class="sort-arrow"></th>
            <th><abbr title="Success Rate">\(\mathcal{S}\)</abbr><span class="sort-arrow"></th>
            <th><abbr title="Coverage Increase">\(\Delta\mathcal{C}\)</abbr><span class="sort-arrow"></th>
            <th>Date <span class="sort-arrow"></th>
            <th><abbr title="Trajectories">Traj.</abbr></th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>SWE-Agent+</td>
            <td>18.5%</td>
            <td>27.6%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://swe-agent.com/latest/">SWE-Agent</a> (Mistral Large 2)</td>
            <td>16.3%</td>
            <td>23.0%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://swe-agent.com/latest/">SWE-Agent</a> (Claude 3.5 Sonnet)</td>
            <td>12.3%</td>
            <td>30.3%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://swe-agent.com/latest/">SWE-Agent</a> (GPT-4o mini)</td>
            <td>9.8%</td>
            <td>20.9%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://swe-agent.com/latest/">SWE-Agent</a> (Claude 3 Haiku)</td>
            <td>2.5%</td>
            <td>3.0%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://swe-agent.com/latest/">SWE-Agent</a> (Mixtral 8x22B)</td>
            <td>0.7%</td>
            <td>0.9%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://swe-agent.com/latest/">SWE-Agent</a> (GPT-4)</td>
            <td>15.9%</td>
            <td>26.5%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://aider.chat">Aider</a> (GPT-4)</td>
            <td>12.7%</td>
            <td>27.8%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td><a href="https://autocoderover.dev">AutoCodeRover</a> (GPT-4)</td>
            <td>9.1%</td>
            <td>17.9%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td>LIBRO</td>
            <td>14.1%</td>
            <td>23.8%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td>GPT-4 + BM25 (ZSP)</td>
            <td>9.4%</td>
            <td>21.5%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
          <tr>
            <td>GPT-4 + BM25 (ZSB)</td>
            <td>3.6%</td>
            <td>7.6%</td>
            <td><time>2024-05-22</time></td>
            <td><a href="https://github.com/logic-star-ai/swt-bench?tab=readme-ov-file#evaluation-results">ðŸ”—</a></td>
          </tr>
        </tbody>
        </table>
        </div></div>

      </div>
    </div>
  </section>
<section class="hero is-small is-link">
  <div class="hero-body">
    <p class="subtitle" style="text-align: center;font-size: small;">
        SWT-Bench is a project by <a href="https://logicstar.ai">Logic Star AI</a> and the <a href="https://www.sri.inf.ethz.ch/">Secure, Reliable, and Intelligent Systems Lab</a> at ETH ZÃ¼rich.<br/>
        <img src="./static/images/institution-logos.svg" class="institution-logo"/>
    </p>
  </div>
</section>
<section class="section" id="about">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: left;">
          <h2 class="title is-4 is-spaced">
          <a class="bd-anchor-link" href="#about"></a>
            What is the task in SWT-Bench?
          </h2>
          <h5 class="subtitle is-5">Generate software tests which reproduce user-reported issues and increase code coverage.</h5>
       <p>Each SWT-Bench task is based on a pull-request from a GitHub repository which resolves a reported issue and contains the code patch fixing the issue and unit tests testing the fix. Given the original state of the code base and the user issue, the task is to generate tests that reproduce this issue. These generated tests are expected to fail on the original code base and pass after the issue is resolved. 
          </p>
        </div>
      </div>
</div>
</div>
</section>
<section class="section">
</div>  
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: left;">
          <h2 class="title is-4 is-spaced">
            <img src="./static/images/overviewfig.svg" class="overviewfig">
          </div>
        </div>
      </div>
</div>
</div>  
</div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: left;">
          <h2 class="title is-4 is-spaced">
          <a class="bd-anchor-link" href="#about"></a>
            What metrics do you report?
          </h2>
          <h5 class="subtitle is-5">We measure whether the generated tests reproduce the user issue and increase the code coverage of the modified code.</h5>
       <p>For a generated test to reproduce the described issue, it should fail on original code base but pass after the code patch fixing the issue is applied. We call this a Fail-to-Pass (F2P) test. An instance is successfully resolved, if at least one F2P test but no test failing on the fixed state of the codebase (F2F or P2F) is generated. We report the success rate \( \mathcal{S}\). We further measure the increase in line coverage of the liens changed when resolving the issue. We call this the Coverage Increase \(\Delta \mathcal{C}\).
          </p>
        </div>
      </div>
</div>
</div>  
<!-- </div>
</section>
<section class="section" id="findings">
</div>  
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: left;">
          <h2 class="title is-4 is-spaced">
          <a class="bd-anchor-link" href="#findings"></a>
            What were the initial findings of SWT-Bench?
          </h2>
          <h5 class="subtitle is-5">Code Agents are highly effective at writing unit tests, even when initially designed for code repair and not specifically adapted.</h5>
          <p>
            We evaluated the performance of bare bone LLMs in a Zero-Shot setting, the heuristic method <a href="https://github.com/coinse/libro/tree/main">LIBRO</a> and various code agents on SWT-Bench. We found that, surprisingly, code agents are highly effective at writing unit tests and even outperformed the previous state-of-the-art LIBRO.
          </p>
        </div>
        </div>
      </div>
</div> -->
</div>  
</section>
<section class="section" id="unittests">
</div>  
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: left;">
          <h2 class="title is-4 is-spaced">
          <a class="bd-anchor-link" href="#unittests"></a>
            What is the value of test generation?
          </h2>
          <h5 class="subtitle is-5">Reproducing test can aide test-driven development, avoid regression, and are a powerful tool to cross-validate proposed bug fixes.</h5>
          <p>
            To resolve a reported issues reliably, it is essential to first reproduce it and then confirm that a proposed bug fix actually addresses it. This is typically done by creating a reproducing test. However creating such tests is a tedious and time consuming process that we want to automate using code agents. Once a reproducing test is generated, it can be used to drive the process of fixing the issue and validate a proposed bug fix.
          </p>
        </div>
        </div>
      </div>
</div>
</div>  
</section>
<section class="section" id="swebench">
</div>  
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: left;">
          <h2 class="title is-4 is-spaced">
          <a class="bd-anchor-link" href="#swebench"></a>
            What is the relationship between SWT-Bench and <a href="https://swebench.com">SWE-bench</a>?
          </h2>
          <h5 class="subtitle is-5">SWT-Bench and SWE-bench measure complimentary skills. SWT-Bench measures the capability of reproducing a reported issue, while SWE-bench measures the capability of fixing the issue.</h5>
          <p>
            SWT-Bench and SWE-bench are based on the same GitHub repositories and issues. While SWT-Bench measures the ability of models or agents to reproduce a given issue, SWE-bench measures their ability to resolve it. We observe that while these tasks are complimentary, their hardness is not correlated on an instance level.
          </p>
        </div>
        </div>
      </div>
</div>
</div>  
</section>
<section class="section" id="learn-more">
</div>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content" style="text-align: left;">
        <h2 class="title is-4 is-spaced">
          <a class="bd-anchor-link" href="#learn-more"></a>
            Check out our paper for more details:
        </h2>
      </div>
          <div class="content" style="text-align: center;">
            <h2 class="title is-3">SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents</h2>
            <span class="team-name"><a href="https://www.sri.inf.ethz.ch/people/niels">Niels MÃ¼ndler</a><sup>1</sup></span>,
            <span class="team-name"><a href="https://www.sri.inf.ethz.ch/people/mark">Mark Niklas MÃ¼ller</a><sup>1,2</sup></span>,
            <span class="team-name"><a href="https://www.sri.inf.ethz.ch/people/jingxuan">Jingxuan He</a><sup>1</sup></span>,
            <span class="team-name"><a href="https://www.sri.inf.ethz.ch/people/martin">Martin Vechev</a><sup>1</sup></span>
            <br/>
            <span class="institution"><sup>1</sup>ETH Zurich</span>
            <span class="institution"><sup>2</sup>Logic Star AI</span>
          </div>
        </div>
      </div>
    </div>
    <br/>
    <br/>
      <div class="columns is-centered">
        <div class="column is-narrow">
          <div class="content" style="text-align: center;">
            <a href="https://arxiv.org/abs/2406.12952">
            <img src="./static/images/emojis/1F4C4.svg" alt="ðŸ“œ" class="paper-code-emoji">
            </br>
            Paper
          </a>
        </div>
        </div>
      <div class="column is-1">
        </div>
      <div class="column is-narrow">
          <div class="content" style="text-align: center;">
    <a href="https://github.com/logic-star-ai/swt-bench"> 
            <img src="./static/images/emojis/logo-github.a1fdb524.svg" alt="ðŸ§‘â€ðŸ’»" class="paper-code-emoji">
    </br>
            Code
    </a>
          </div>
    </div>
    </div>
    </div>
</section>
<section class="section" id="citation">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
<div class="column">
  <div class="content">
    <h2 class="title is-4 is-spaced">
    <a class="bd-anchor-link" href="#citation"></a>
      Citing this work
    </h2>
    <p>If you use this benchmark, please cite:</p>
  <pre>
<code class="language-bib" id="citation-code"> @inproceedings{mundler2024swtbench,
  title={{SWT}-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents},
  author={Niels M{\"u}ndler and Mark Niklas Mueller and Jingxuan He and Martin Vechev},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024},
  url={https://openreview.net/forum?id=9Y8zUO11EQ}
}</code>
</pre>
  </div>
</div>
</div>
  </div>
</div>
</section>
<section class="section custom-footer">
  <div class="container is-max-desktop content">
    <div class="columns">
      <div class="column">
          SWT-Bench is a project by <a href="https://logicstar.ai">Logic Star AI</a> and the <a href="https://www.sri.inf.ethz.ch/">Secure, Reliable, and Intelligent Systems Lab</a> at ETH ZÃ¼rich.<br/>
          <img src="static/images/institution-logos-black.svg"/>
      </div>
      <div class="column" style="text-align: left;">
        Site template adapted from <a href="https://lmql.ai">LMQL</a> and uses <a href="https://bulma.io/">Bulma</a>.
        All emojis designed by <a href="https://openmoji.org/">OpenMoji</a> â€“ the open-source emoji and icon project. License: <a href="https://creativecommons.org/licenses/by-sa/4.0/#">CC BY-SA 4.0</a><br/>
        Last updated on <time>2024-12-14</time>.<br/>
      </div>
    </div>
  </div>
</section>

<script>
  document.getElementById('citation-code').addEventListener('click', function() {
    selectElement(this);
  });
</script>



</body>
</html>
